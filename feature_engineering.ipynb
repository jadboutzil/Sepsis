{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "caeacc44",
   "metadata": {},
   "source": [
    "### Feature engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b8a8f0d",
   "metadata": {},
   "source": [
    "This notebook takes the raw clinical data and builds corresponding features. There are a mix of continuous and categorical variables from the clinical data, and some contain more missing values than others.\n",
    "\n",
    "The general strategy is to window the data into 10 hour blocks, with a one hour prediction of sepsis/no sepsis. For each window, the following variables are retained as time series:\n",
    "- HR\n",
    "- MAP\n",
    "- O2Sat\n",
    "- SBP\n",
    "- Resp\n",
    "\n",
    "The remainder of the variables are summarized as a single value, the median of the ten values in that window. This is a strategy to deal with the fact that there may be > 90% missing data for some variables. Pas necessaire d'éxecuter ce notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b6e02b20",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pdb\n",
    "import os\n",
    "import shutil\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "71f31635",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    if os.path.exists('feats'):\n",
    "        shutil.rmtree('feats')\n",
    "    os.makedirs('feats')\n",
    "except Exception as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3684110e",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -U -q PyDrive2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "304451da",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydrive2.auth import GoogleAuth\n",
    "\n",
    "from pydrive2.drive import GoogleDrive\n",
    "\n",
    "from google.colab import auth\n",
    "\n",
    "from oauth2client.client import GoogleCredentials\n",
    "\n",
    "auth.authenticate_user()\n",
    "\n",
    "gauth = GoogleAuth()\n",
    "\n",
    "gauth.credentials = GoogleCredentials.get_application_default()\n",
    "\n",
    "drive = GoogleDrive(gauth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1a3437b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://drive.google.com/file/d/14zYhaPPm0xSNTCvd0zluht_GM_3uwWF6/view?usp=sharing\n",
    "fileDownloaded = drive.CreateFile({'id':'14zYhaPPm0xSNTCvd0zluht_GM_3uwWF6'})\n",
    "fileDownloaded.GetContentFile('combined1.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "012b5107",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_pickle(\"combined1.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "afe52457",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>HR</th>\n",
       "      <th>O2Sat</th>\n",
       "      <th>Temp</th>\n",
       "      <th>SBP</th>\n",
       "      <th>MAP</th>\n",
       "      <th>DBP</th>\n",
       "      <th>Resp</th>\n",
       "      <th>EtCO2</th>\n",
       "      <th>BaseExcess</th>\n",
       "      <th>HCO3</th>\n",
       "      <th>...</th>\n",
       "      <th>Fibrinogen</th>\n",
       "      <th>Platelets</th>\n",
       "      <th>Age</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Unit1</th>\n",
       "      <th>Unit2</th>\n",
       "      <th>HospAdmTime</th>\n",
       "      <th>ICULOS</th>\n",
       "      <th>SepsisLabel</th>\n",
       "      <th>patient</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>83.14</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.03</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>p000001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>97.0</td>\n",
       "      <td>95.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>98.0</td>\n",
       "      <td>75.33</td>\n",
       "      <td>NaN</td>\n",
       "      <td>19.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>83.14</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.03</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>p000001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>89.0</td>\n",
       "      <td>99.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>122.0</td>\n",
       "      <td>86.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>22.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>83.14</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.03</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>p000001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>90.0</td>\n",
       "      <td>95.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>30.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>24.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>83.14</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.03</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>p000001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>103.0</td>\n",
       "      <td>88.5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>122.0</td>\n",
       "      <td>91.33</td>\n",
       "      <td>NaN</td>\n",
       "      <td>24.5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>83.14</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.03</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>p000001</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 42 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      HR  O2Sat  Temp    SBP    MAP  DBP  Resp  EtCO2  BaseExcess  HCO3  ...  \\\n",
       "0    NaN    NaN   NaN    NaN    NaN  NaN   NaN    NaN         NaN   NaN  ...   \n",
       "1   97.0   95.0   NaN   98.0  75.33  NaN  19.0    NaN         NaN   NaN  ...   \n",
       "2   89.0   99.0   NaN  122.0  86.00  NaN  22.0    NaN         NaN   NaN  ...   \n",
       "3   90.0   95.0   NaN    NaN    NaN  NaN  30.0    NaN        24.0   NaN  ...   \n",
       "4  103.0   88.5   NaN  122.0  91.33  NaN  24.5    NaN         NaN   NaN  ...   \n",
       "\n",
       "   Fibrinogen  Platelets    Age  Gender  Unit1  Unit2  HospAdmTime  ICULOS  \\\n",
       "0         NaN        NaN  83.14       0    NaN    NaN        -0.03       1   \n",
       "1         NaN        NaN  83.14       0    NaN    NaN        -0.03       2   \n",
       "2         NaN        NaN  83.14       0    NaN    NaN        -0.03       3   \n",
       "3         NaN        NaN  83.14       0    NaN    NaN        -0.03       4   \n",
       "4         NaN        NaN  83.14       0    NaN    NaN        -0.03       5   \n",
       "\n",
       "   SepsisLabel  patient  \n",
       "0            0  p000001  \n",
       "1            0  p000001  \n",
       "2            0  p000001  \n",
       "3            0  p000001  \n",
       "4            0  p000001  \n",
       "\n",
       "[5 rows x 42 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cb45283f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentage Missing:\n",
      "HR                  0.098857\n",
      "O2Sat               0.130635\n",
      "Temp                0.661465\n",
      "SBP                 0.145699\n",
      "MAP                 0.124523\n",
      "DBP                 0.313383\n",
      "Resp                0.153566\n",
      "EtCO2               0.962979\n",
      "BaseExcess          0.945823\n",
      "HCO3                0.958127\n",
      "FiO2                0.916660\n",
      "pH                  0.930716\n",
      "PaCO2               0.944377\n",
      "SaO2                0.965488\n",
      "AST                 0.983772\n",
      "BUN                 0.931373\n",
      "Alkalinephos        0.983927\n",
      "Calcium             0.941151\n",
      "Chloride            0.954634\n",
      "Creatinine          0.939058\n",
      "Bilirubin_direct    0.998071\n",
      "Glucose             0.828941\n",
      "Lactate             0.973322\n",
      "Magnesium           0.936896\n",
      "Phosphate           0.959864\n",
      "Potassium           0.906892\n",
      "Bilirubin_total     0.985090\n",
      "TroponinI           0.990484\n",
      "Hct                 0.911472\n",
      "Hgb                 0.926161\n",
      "PTT                 0.970548\n",
      "WBC                 0.935932\n",
      "Fibrinogen          0.993391\n",
      "Platelets           0.940583\n",
      "Age                 0.000000\n",
      "Gender              0.000000\n",
      "Unit1               0.394112\n",
      "Unit2               0.394112\n",
      "HospAdmTime         0.000005\n",
      "ICULOS              0.000000\n",
      "SepsisLabel         0.000000\n",
      "patient             0.000000\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "#get the percentage missing for each column\n",
    "print('Percentage Missing:')\n",
    "print(df.isna().sum()/len(df))\n",
    "\n",
    "#columns to drop\n",
    "#drop Unit2 because Unit1 and Unit2 are mutually exclusive\n",
    "#drop ICULOS as it's basically just an index\n",
    "cols_to_drop = ['Unit2', 'ICULOS']\n",
    "df = df.drop(cols_to_drop, axis=1)\n",
    "\n",
    "#columns with < 15% missing data, and continuous data. these will be retained as time series\n",
    "cols_cont = ['HR', 'MAP', 'O2Sat', 'SBP', 'Resp']\n",
    "\n",
    "#columns with continuous data and > 15% missing data\n",
    "cols_to_bin = ['Unit1', 'Gender', 'HospAdmTime', 'Age', 'DBP', 'Temp', 'Glucose', 'Potassium', 'Hct', 'FiO2', 'Hgb', 'pH', 'BUN', 'WBC', 'Magnesium', 'Creatinine', 'Platelets', 'Calcium', 'PaCO2', 'BaseExcess', 'Chloride', 'HCO3', 'Phosphate', 'EtCO2', 'SaO2', 'PTT', 'Lactate', 'AST', 'Alkalinephos', 'Bilirubin_total', 'TroponinI', 'Fibrinogen', 'Bilirubin_direct']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "612907a2",
   "metadata": {},
   "source": [
    "Calculate the mean/std for standardization for each variable. Leave out a random 8000 patients as the test set. In other words don't include a random 4000 patients when calculating the mean/std scaling parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b9b3c7cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "patients_training_data = df['patient'].unique()\n",
    "np.random.shuffle(patients_training_data)\n",
    "patients_training_data = patients_training_data[0:-6000]\n",
    "\n",
    "df_mean_std = df[df['patient'].isin(patients_training_data)].describe().loc[['mean', 'std']]\n",
    "df_mean_std.to_pickle('mean_std_scaling.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bb32d3f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of positive training examples:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "47270"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('Number of positive training examples:')\n",
    "sum(df[df['patient'].isin(patients_training_data)]['SepsisLabel']==1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4408cfa1",
   "metadata": {},
   "source": [
    "Loop through each subject and grab a window of 10 hours, with an output label associated with the 11th hour (ie predict one hour ahead)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6260a554",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "patient 500\n",
      "patient 1000\n",
      "patient 1500\n",
      "patient 2000\n",
      "patient 2500\n",
      "patient 3000\n",
      "patient 3500\n",
      "patient 4000\n",
      "patient 4500\n",
      "patient 5000\n",
      "patient 5500\n",
      "patient 6000\n",
      "patient 6500\n",
      "patient 7000\n",
      "patient 8000\n",
      "patient 8500\n",
      "patient 9000\n",
      "patient 9500\n",
      "patient 10000\n",
      "patient 10500\n",
      "patient 11000\n",
      "patient 11500\n",
      "patient 12000\n",
      "patient 12500\n",
      "patient 13000\n",
      "patient 13500\n",
      "patient 14000\n",
      "patient 14500\n",
      "patient 15000\n",
      "patient 15500\n",
      "patient 16000\n",
      "patient 16500\n",
      "patient 17000\n",
      "patient 17500\n",
      "patient 18000\n",
      "patient 18500\n",
      "patient 19000\n",
      "patient 19500\n",
      "patient 20000\n",
      "patient 20500\n",
      "patient 500\n",
      "patient 1000\n",
      "patient 1500\n",
      "patient 2000\n",
      "patient 2500\n",
      "patient 3000\n",
      "patient 3500\n",
      "patient 4000\n",
      "patient 4500\n",
      "patient 5000\n",
      "patient 5500\n",
      "patient 6000\n",
      "patient 6500\n",
      "patient 7000\n",
      "patient 7500\n",
      "patient 8000\n",
      "patient 8500\n",
      "patient 9000\n",
      "patient 9500\n",
      "patient 10000\n",
      "patient 10500\n",
      "patient 11000\n",
      "patient 11500\n",
      "patient 12000\n",
      "patient 12500\n",
      "patient 13000\n",
      "patient 13500\n",
      "patient 14000\n",
      "patient 14500\n",
      "patient 15000\n",
      "patient 15500\n",
      "patient 16000\n",
      "patient 16500\n",
      "patient 17000\n",
      "patient 17500\n",
      "patient 18000\n",
      "patient 18500\n",
      "patient 19000\n",
      "patient 19500\n",
      "patient 20000\n"
     ]
    }
   ],
   "source": [
    "#loop through each patient at a time\n",
    "save_count = 0\n",
    "windowed_df_list = []\n",
    "grouped_by_patient = df.groupby('patient')\n",
    "for patient, group in grouped_by_patient:\n",
    "    #print(patient)\n",
    "    group = group.reset_index(drop=True)\n",
    "\n",
    "    #backfill any missing values for the continuous variables with < 15% missing data\n",
    "    group['HR'] = group['HR'].bfill().ffill()\n",
    "    group['MAP'] = group['MAP'].bfill().ffill()\n",
    "    group['O2Sat'] = group['O2Sat'].bfill().ffill()\n",
    "    group['SBP'] = group['SBP'].bfill().ffill()\n",
    "    group['Resp'] = group['Resp'].bfill().ffill()\n",
    "    \n",
    "    #standardize the continous data\n",
    "    group = group.assign(HR=(group['HR']-df_mean_std['HR']['mean'])/(df_mean_std['HR']['std']))\n",
    "    group = group.assign(MAP=(group['MAP']-df_mean_std['MAP']['mean'])/(df_mean_std['MAP']['std']))\n",
    "    group = group.assign(O2Sat=(group['O2Sat']-df_mean_std['O2Sat']['mean'])/(df_mean_std['O2Sat']['std']))\n",
    "    group = group.assign(SBP=(group['SBP']-df_mean_std['SBP']['mean'])/(df_mean_std['SBP']['std']))\n",
    "    group = group.assign(Resp=(group['Resp']-df_mean_std['Resp']['mean'])/(df_mean_std['Resp']['std']))\n",
    "\n",
    "    #generate windows of 10 hours, predicting one sample into the future\n",
    "    windowed_data = []\n",
    "    N = len(group)\n",
    "    win_len = 10\n",
    "    pred_len = 1\n",
    "    i = 0\n",
    "    while(i+win_len+pred_len <= N):\n",
    "        tmp_data = group.iloc[i:i+win_len]\n",
    "        tmp_label = group.iloc[i+win_len:i+win_len+pred_len]\n",
    "        tmp_label = int(any(tmp_label['SepsisLabel']))\n",
    "        tmp_patient = patient\n",
    "\n",
    "        #slide the window forward\n",
    "        i = i+1\n",
    "\n",
    "        #get all the continuous variables into one group\n",
    "        X_cont = tmp_data[cols_cont]\n",
    "        X_cont = X_cont.values\n",
    "\n",
    "        #if any of the continuous variables is nan (in other words, there wasn't even a single value to \n",
    "        #backfill/forwardfill) then just skip this window\n",
    "        if np.isnan(X_cont).any(): continue\n",
    "\n",
    "        #process each of the variables to be binned\n",
    "        X_binned_dict = {}\n",
    "        for col_to_bin in cols_to_bin:\n",
    "            tmp_val = tmp_data[col_to_bin].median()\n",
    "            if col_to_bin not in ['Gender', 'Unit1']:\n",
    "                tmp_val = (tmp_val-df_mean_std[col_to_bin]['mean'])/df_mean_std[col_to_bin]['std']\n",
    "                \n",
    "            X_binned_dict[col_to_bin] = tmp_val\n",
    "        \n",
    "        #package it all into a dictionary\n",
    "        tmp_dict = X_binned_dict\n",
    "        tmp_dict['X_cont'] = X_cont\n",
    "        tmp_dict['label'] = tmp_label\n",
    "        tmp_dict['patient'] = tmp_patient\n",
    "        windowed_data.append(tmp_dict)\n",
    "        \n",
    "    #append the dataframe to the list of dataframes\n",
    "    windowed_data_df = pd.DataFrame(windowed_data)\n",
    "    windowed_df_list.append(windowed_data_df)\n",
    "\n",
    "    #periodically save every 500 patients\n",
    "    if (int(patient[-5:]) % 500) == 0:\n",
    "        print('patient %i' % int(patient[-5:]))\n",
    "        windowed_df = pd.concat(windowed_df_list).reset_index(drop=True)\n",
    "        train = windowed_df[windowed_df['patient'].isin(patients_training_data)].drop('patient', axis=1)\n",
    "        test = windowed_df[~windowed_df['patient'].isin(patients_training_data)].drop('patient', axis=1)\n",
    "\n",
    "        train.to_pickle('feats/train_%i.pkl' % save_count)\n",
    "        test.to_pickle('feats/test_%i.pkl' % save_count)\n",
    "\n",
    "        windowed_df_list = []\n",
    "        save_count = save_count+1\n",
    "\n",
    "#save any remaining data\n",
    "if len(windowed_df_list) > 0:\n",
    "    #separate the training and testing data\n",
    "    windowed_df = pd.concat(windowed_df_list).reset_index(drop=True)\n",
    "    train = windowed_df[windowed_df['patient'].isin(patients_training_data)].drop('patient', axis=1)\n",
    "    test = windowed_df[~windowed_df['patient'].isin(patients_training_data)].drop('patient', axis=1)\n",
    "\n",
    "    train.to_pickle('feats/train_%i.pkl' % save_count)\n",
    "    test.to_pickle('feats/test_%i.pkl' % save_count)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
